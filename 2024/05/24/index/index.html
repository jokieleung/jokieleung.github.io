<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Zujie Liang</title><meta name="author" content="Zujie Liang"><link rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><header id="page_header"><div class="header_wrap"><div id="blog_name"><a class="blog_title" id="site-name" href="/">Zujie Liang</a></div><button class="menus_icon"><div class="navicon"></div></button><ul class="menus_items"><li class="menus_item"><a class="site-page" href="/#News"> News</a></li><li class="menus_item"><a class="site-page" href="/#Publications"> Publications</a></li><li class="menus_item"><a class="site-page" href="/#Work-Experiences"> Experiences</a></li></ul></div></header><main id="page_main"><div class="side-card sticky"><div class="card-wrap" itemscope itemtype="http://schema.org/Person"><div class="author-avatar"><img class="avatar-img" src="/img/jokieProfile.jpg" onerror="this.onerror=null;this.src='/img/avatar_jokie.jpg'" alt="avatar"></div><div class="author-discrip"><h3>Zujie Liang</h3><p class="author-bio">To the stars, through hardships.</p></div><div class="author-links"><button class="btn m-social-links">Links</button><ul class="social-icons"><li><a class="social-icon" href="https://twitter.com/liangzujie" target="_blank"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://github.com/jokieleung" target="_blank"><i class="fab fa-github" aria-hidden="true"></i></a></li><li><a class="social-icon" href="https://www.linkedin.com/in/zujie-liang-0b7b55158/" target="_blank"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="social-icon" href="mailto:jokieleung@outlook.com" target="_blank"><i class="fas fa-envelope" aria-hidden="true"></i></a></li></ul><ul class="social-links"><li><a class="e-social-link" href="https://scholar.google.com/citations?user=27G-km8AAAAJ&amp;hl=en" target="_blank"><i class="fas fa-graduation-cap" aria-hidden="true"></i><span>Google Scholar</span></a></li></ul></div><a class="cv-links" href="/attaches/Zujie_Liang_CV.pdf" target="_blank"><i class="fas fa-file-pdf" aria-hidden="true"><span>Curriculum Vitae</span></i></a></div></div><div class="page" itemscope itemtype="http://schema.org/CreativeWork"><h2 class="page-title">about me</h2><article><h1 id="Bio"><a href="#Bio" class="headerlink" title="Bio"></a>Bio</h1><p>My name is Zujie Liang (Ê¢ÅÁ•ñÊù∞). I am currently a Senior R&amp;D AI Engineer at <a href="https://www.antgroup.com/en" target="_blank" rel="noopener">Ant Group</a> (FinTech giant in China). Now I am building LLM-based Agents to improve credit business including User Understanding, Knowledge Graph, Recommender System, and Risk Management. I have published 10+ papers at the top international AI conferences such as ICLR, ACL, EMNLP, SIGIR, CIKM. Before that, I obtained my M.S. degree from <a href="https://www.sysu.edu.cn/" target="_blank" rel="noopener">Sun Yat-Sen University (SYSU)</a> in 2022.</p>
<p>My current research interestsüî¨ focus on:</p>
<ul>
<li><p><strong>LLM&#x2F;VLM Agents</strong>: Building useful LLM&#x2F;VLM Agents that leverage agentic capabilities to solve real-world tasks, including Agentic Memory <a href="https://arxiv.org/abs/2502.12110" target="_blank" rel="noopener">[A-MEM]</a>, Agentic AutoML <a href="https://arxiv.org/abs/2502.14693" target="_blank" rel="noopener">[I-MCTS]</a>, Shopping Agents <a href="https://arxiv.org/abs/2502.14662" target="_blank" rel="noopener">[iAgent]</a><a href="http://arxiv.org/abs/2109.12302" target="_blank" rel="noopener">[NTRD]</a>, Multimodal Agents <a href="https://arxiv.org/abs/2105.13073" target="_blank" rel="noopener">[Maria]</a> (Probably one of the earliest attempts at VLM-based agents).</p>
</li>
<li><p><strong>LLM Post-training</strong>: Exploring post-training, dedicated to efficient knowledge distillation <a href="https://arxiv.org/abs/2405.17890" target="_blank" rel="noopener">[SLMRec]</a>, alleviating the hallucination <a href="https://arxiv.org/abs/2406.10881" target="_blank" rel="noopener">[CoKE]</a>, and enhancing the reasoning capabilities <a href="https://arxiv.org/abs/2412.12609" target="_blank" rel="noopener">[MultiLingPoT]</a>.</p>
</li>
<li><p><strong>Long Context Processing</strong>: Enhancing the long context capablities of LLMs through sparse attention design <a href="https://arxiv.org/abs/2503.03588" target="_blank" rel="noopener">[PowerAttention]</a> and context management framework <a href="https://arxiv.org/abs/2410.06519" target="_blank" rel="noopener">[SEGMENT+]</a>.</p>
</li>
<li><p><strong>LLM PEFT</strong>: Developing practical approaches for effectively continual training <a href="https://aclanthology.org/2023.acl-long.16.pdf" target="_blank" rel="noopener">[Lottery Prompt]</a> and multi-task learning <a href="https://dl.acm.org/doi/10.1145/3583780.3614913" target="_blank" rel="noopener">[HPT]</a>.</p>
</li>
<li><p><strong>LLM Benchmarking</strong>: Benchmarking the performance of LLMs on several KG tasks, including Concept Reasoning <a href="https://aclanthology.org/2024.findings-acl.815.pdf" target="_blank" rel="noopener">[CR-LLM]</a>, Historical Analogy <a href="https://arxiv.org/abs/2409.14820" target="_blank" rel="noopener">[PmP]</a>, and Quotation Generation <a href="https://arxiv.org/abs/2411.03675" target="_blank" rel="noopener">[QUILL]</a>.</p>
</li>
<li><p><strong>Multimodal Hallucination</strong>: Focusing on alleviating the multimodal hallucination caused by modality bias. <a href="https://arxiv.org/abs/2105.14300" target="_blank" rel="noopener">[LPF]</a><a href="https://www.aclweb.org/anthology/2020.emnlp-main.265.pdf" target="_blank" rel="noopener">[CL-VQA]</a></p>
</li>
</ul>
<p>I‚Äôm always open to discussion or collaboration. Please check my <a href="attaches/Zujie_Liang_CV.pdf" target="_blank">CV</a> for latest update and drop me an <a href="mailto:jokieleung@outlook.com">E-mail</a> if you‚Äôre interested.</p>
<h1 id="News"><a href="#News" class="headerlink" title="News"></a>News</h1><ul>
<li>[08&#x2F;2025] One paper is accepted by EMNLP 2025.</li>
<li>[07&#x2F;2025] <a href="https://arxiv.org/abs/2409.14820" target="_blank" rel="noopener">Our paper</a> on LLM Historical Analogy received an <a href="https://2025.aclweb.org/program/awards/" target="_blank" rel="noopener">Outstanding Paper Award</a> (Top 0.3%) in ACL 2025, Congrats to Nianqi!</li>
<li>[05&#x2F;2025] 2 papers are accepted by ACL 2025.</li>
<li>[01&#x2F;2025] One paper is accepted by ICLR 2025.</li>
<li>[09&#x2F;2024] One paper is accepted by EMNLP 2024.</li>
<li>[05&#x2F;2024] One paper is accepted by Findings of ACL 2024.</li>
<li>[08&#x2F;2023] One paper is accepted by CIKM 2023.</li>
<li>[06&#x2F;2023] Hosted Ant FinTech AI Challenge (AFAC2023) at <a href="https://tianchi.aliyun.com/competition/entrance/532088/introduction" target="_blank" rel="noopener">TIANCHI</a>.</li>
<li>[05&#x2F;2023] One paper about Lottery Prompt Tuning is accepted by ACL 2023.</li>
<li>[07&#x2F;2022] I start my journey at Ant Group.</li>
<li>[04&#x2F;2022] One paper is accepted by ICMR 2022.</li>
<li>[08&#x2F;2021] One paper on recommender dialogue system is accepted by EMNLP 2021.</li>
<li>[06&#x2F;2021] I am offered an ACM SIGIR 2021 Student Travel Grant.</li>
<li>[06&#x2F;2021] I serve as PC Member for NLPCC 2021.</li>
<li>[05&#x2F;2021] One paper on visual knowledge powered conversational agent is accepted by ACL 2021.</li>
<li>[03&#x2F;2021] One paper on De-biased VQA is accepted by SIGIR 2021.</li>
<li>[09&#x2F;2020] One paper on Robust VQA is accepted by EMNLP 2020.</li>
</ul>
<h1 id="Work-Experiences"><a href="#Work-Experiences" class="headerlink" title="Work Experiences"></a>Work Experiences</h1><ul>
<li>Ant Group,<br>Senior R&amp;D AI Engineer, July. 2022 - Present. </li>
<li>Alibaba,<br>Ads Algorithm Intern, June. 2021 - Sept. 2021.   </li>
<li>Microsoft,<br>Research Intern, Oct. 2020 - June. 2021. </li>
<li>Huawei,<br>SDE Intern, Jun. 2018 - Sept. 2018.</li>
</ul>
<h1 id="Publications"><a href="#Publications" class="headerlink" title="Publications"></a>Publications</h1><h2 id="LLM-x2F-VLM-Agents"><a href="#LLM-x2F-VLM-Agents" class="headerlink" title="LLM&#x2F;VLM Agents"></a>LLM&#x2F;VLM Agents</h2><ul>
<li><p><strong>A-MEM: Agentic Memory for LLM Agents</strong><br>  Wujiang Xu,¬†<strong>Zujie Liang</strong>, Kai Mei, Hang Gao, Juntao Tan, Yongfeng Zhang<br>  <strong>preprint</strong>.¬†<a href="https://arxiv.org/abs/2502.12110" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/WujiangXu/A-mem" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</strong><br>  <strong>Zujie Liang</strong>, Feng Wei, Wujiang Xu, Lin Chen, Yuxi Qian, Xinhui Wu<br>  <strong>preprint</strong>. <a href="https://arxiv.org/abs/2502.14693" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/jokieleung/I-MCTS" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>iAgent: LLM Agent as a Shield between User and Recommender Systems</strong><br>  Wujiang Xu, Yunxiao Shi,¬†<strong>Zujie Liang</strong>, Xuying Ning, Kai Mei, Kun Wang, Xi Zhu, Min Xu, Yongfeng Zhang<br>  <strong>ACL 2025</strong> (Findings).¬†<a href="https://arxiv.org/abs/2502.14662" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/WujiangXu/iAgent" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Maria: A Visual Experience Powered Conversational Agent</strong><br>  <strong>Zujie Liang</strong>, Huang Hu, Can Xu, Chongyang Tao, Xiubo Geng, Yining Chen, Fan Liang, Daxin Jiang.<br>  <strong>ACL 2021</strong>.¬†<a href="https://arxiv.org/abs/2105.13073" target="_blank" rel="noopener">[paper]</a><a href="https://jokieleung.github.io/attaches/ACL-2021-slides.pdf">[slides]</a><a href="https://github.com/jokieleung/Maria" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Learning Neural Templates for Recommender Dialogue System</strong><br>  <strong>Zujie Liang</strong><em>, Huang Hu</em>, Can Xu, Jian Miao, Yingying He, Yining Chen, Xiubo Geng, Fan Liang, Daxin Jiang<br>  <strong>EMNLP 2021</strong>.¬†<a href="http://arxiv.org/abs/2109.12302" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/jokieleung/NTRD" target="_blank" rel="noopener">[code]</a></p>
</li>
</ul>
<h2 id="LLM-Post-training"><a href="#LLM-Post-training" class="headerlink" title="LLM Post-training"></a>LLM Post-training</h2><ul>
<li><p><strong>SLMRec: Distilling Large Language Models into Small for Sequential Recommendation</strong><br>  Wujiang Xu, Qitian Wu,¬†<strong>Zujie Liang</strong>, Jiaojiao Han, Xuying Ning, Yunxiao Shi, Wenfang Lin, Yongfeng Zhang<br>  <strong>ICLR 2025</strong>.¬†<a href="https://arxiv.org/abs/2405.17890" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/WujiangXu/SLMRec" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Teaching Large Language Models to Express Knowledge Boundary from Their Own Signals</strong><br>  Lida Chen,¬†<strong>Zujie Liang</strong>, Xintao Wang, Jiaqing Liang, Yanghua Xiao, Feng Wei, Jinglei Chen, Zhenghong Hao, Bing Han, Wei Wang<br>  <strong>ACL 2025, KnowFM Workshop</strong>.¬†<a href="https://arxiv.org/abs/2406.10881" target="_blank" rel="noopener">[paper]</a></p>
</li>
<li><p><strong>MultiLingPoT: Enhancing Mathematical Reasoning with Multilingual Program Fine-tuning</strong><br>  Nianqi Li,¬†<strong>Zujie Liang</strong>, Siyu Yuan, Jiaqing Liang, Feng Wei, Yanghua Xiao<br>  <strong>EMNLP 2025</strong> (Findings).¬†<a href="https://arxiv.org/abs/2412.12609" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/jokieleung/MultiLingPoT" target="_blank" rel="noopener">[code]</a></p>
</li>
</ul>
<h2 id="Long-context-LLM"><a href="#Long-context-LLM" class="headerlink" title="Long-context LLM"></a>Long-context LLM</h2><ul>
<li><p><strong>PowerAttention: Exponentially Scaling of Receptive Fields for Effective Sparse Attention</strong><br>  Lida Chen, Dong Xu, Chenxin An, Xintao Wang, Yikai Zhang, Jiangjie Chen, <strong>Zujie Liang</strong>, Feng Wei, Jiaqing Liang, Yanghua Xiao, Wei Wang<br>  <strong>preprint</strong>.¬†<a href="https://arxiv.org/pdf/2503.03588" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/w568w/PowerAttention" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Segment+: Long Text Processing with Short-Context Language Models</strong><br>  Wei Shi, Shuang Li, Kerun Yu, Jinglei Chen,¬†<strong>Zujie Liang</strong>, Xinhui Wu, Yuxi Qian, Feng Wei, Bo Zheng, Jiaqing Liang, Jiangjie Chen, Yanghua Xiao<br>  <strong>EMNLP 2024</strong>.¬†<a href="https://arxiv.org/abs/2410.06519" target="_blank" rel="noopener">[paper]</a></p>
</li>
</ul>
<h2 id="LLM-PEFT"><a href="#LLM-PEFT" class="headerlink" title="LLM PEFT"></a>LLM PEFT</h2><ul>
<li><p><strong>Prompts Can Play Lottery Tickets Well: Achieving Lifelong Learning Information Extraction via Lottery Prompt Tuning</strong><br>  <strong>Zujie Liang</strong>, Feng Wei, Jie Yin, Yuxi Qian, Zhenghong Hao, Bing Han.</p>
<p>  <strong>ACL 2023</strong>.¬†<a href="https://aclanthology.org/2023.acl-long.16.pdf" target="_blank" rel="noopener">[paper]</a><a href="https://github.com/jokieleung/Lottery_Prompt" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Hierarchical Prompt Tuning for Few-Shot Multi-Task Learning</strong><br>  Jingping Liu, Tao Chen,¬†<strong>Zujie Liang</strong>, Haiyun Jiang, Yanghua Xiao, Feng Wei, Yuxi Qian, Zhenghong Hao, Bing Han.<br>  <strong>CIKM 2023</strong>.¬†<a href="https://dl.acm.org/doi/10.1145/3583780.3614913" target="_blank" rel="noopener">[paper]</a></p>
</li>
</ul>
<h2 id="LLM-Benchmarking"><a href="#LLM-Benchmarking" class="headerlink" title="LLM Benchmarking"></a>LLM Benchmarking</h2><ul>
<li><p><strong>CR-LLM: A Dataset and Optimization for Concept Reasoning of Large Language Models</strong><br>  Nianqi Li, Jingping Liu, Sihang Jiang, Haiyun Jiang, Yanghua Xiao, Jiaqing Liang,¬†<strong>Zujie Liang</strong>, Feng Wei, Jinglei Chen, Zhenghong Hao, Bing Han<br>  <strong>ACL 2024</strong>¬†(Findings).¬†<a href="https://aclanthology.org/2024.findings-acl.815.pdf" target="_blank" rel="noopener">[paper]</a></p>
</li>
<li><p><strong>Past Meets Present: Creating Historical Analogy with Large Language Models</strong><br>  Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei,¬†<strong>Zujie Liang</strong>, Deqing Yang, Yanghua Xiao<br>  <strong>ACL 2025, oral</strong>.¬†<a href="https://arxiv.org/abs/2409.14820" target="_blank" rel="noopener">[paper]</a><a href="https://2025.aclweb.org/program/awards/" target="_blank" rel="noopener">[Outstanding Paper Award]</a>(Top 0.3%)</p>
</li>
<li><p><strong>QUILL: Quotation Generation Enhancement of Large Language Models</strong><br>  Jin Xiao, Bowei Zhang, Qianyu He, Jiaqing Liang, Feng Wei, Jinglei Chen,¬†<strong>Zujie Liang</strong>, Deqing Yang, Yanghua Xiao<br>  <strong>preprint</strong>.¬†<a href="https://arxiv.org/abs/2411.03675" target="_blank" rel="noopener">[paper]</a></p>
</li>
</ul>
<h2 id="Multimodal-Hallucination"><a href="#Multimodal-Hallucination" class="headerlink" title="Multimodal Hallucination"></a>Multimodal Hallucination</h2><ul>
<li><p><strong>LPF: A Language-Prior Feedback Objective Function for De-biased Visual Question Answering</strong><br>  <strong>Zujie Liang</strong>, Haifeng Hu, Jiaying Zhu.<br>  <strong>SIGIR 2021</strong>.¬†<a href="https://arxiv.org/abs/2105.14300" target="_blank" rel="noopener">[paper]</a><a href="https://jokieleung.github.io/attaches/LPF_SIGIR21_slides.pdf">[slides]</a><a href="https://github.com/jokieleung/LPF-VQA" target="_blank" rel="noopener">[code]</a></p>
</li>
<li><p><strong>Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering</strong><br>  <strong>Zujie Liang</strong>, Weitao Jiang, Haifeng Hu, Jiaying Zhu.<br>  <strong>EMNLP 2020</strong>.¬†<a href="https://www.aclweb.org/anthology/2020.emnlp-main.265.pdf" target="_blank" rel="noopener">[paper]</a><a href="https://jokieleung.github.io/attaches/Learning_to_Contrast_EMNLP_2020_slides.pdf">[slides]</a><a href="https://github.com/jokieleung/CL-VQA" target="_blank" rel="noopener">[code]</a></p>
</li>
</ul>
<h1 id="Academic-Services"><a href="#Academic-Services" class="headerlink" title="Academic Services"></a>Academic Services</h1><ul>
<li>Reviewer: ARR 2025, ARR 2024, ICLR 2023, EACL 2023, ACL 2022, NLPCC 2022, NLPCC 2021, IJCAI 2021</li>
</ul>
<h1 id="Miscellanous"><a href="#Miscellanous" class="headerlink" title="Miscellanous"></a>Miscellanous</h1><ul>
<li>In my spare time, I maintain <a href="https://github.com/jokieleung/awesome-visual-question-answering" target="_blank" rel="noopener">Awesome-Visual-Question-Answering</a>, which is a curated list of papers in the field of Visual QA (660+ stars now). </li>
<li>Fan of basketball&#x2F;NBA. I am impressed by the application progress of AI in <a href="https://becominghuman.ai/5-game-changing-computer-vision-applications-in-sports-5f02ec35529b" target="_blank" rel="noopener">basketball</a>, such as the <a href="https://www.homecourt.ai/" target="_blank" rel="noopener">HomeCourt</a> APP.</li>
<li><a href="https://www.imdb.com/title/tt2575988/" target="_blank" rel="noopener">Silicon Valley</a> is the funniest TV series. <a href="https://www.imdb.com/title/tt2085059/" target="_blank" rel="noopener">Black Mirror</a> is fantastic too.</li>
</ul>
</article></div></main><div class="nav-wrap"><div class="nav"><button class="site-nav"><div class="navicon"></div></button><ul class="nav_items"><li class="nav_item"><a class="nav-page" href="/#News"> News</a></li><li class="nav_item"><a class="nav-page" href="/#Publications"> Publications</a></li><li class="nav_item"><a class="nav-page" href="/#Work-Experiences"> Experiences</a></li></ul></div><div class="cd-top"><i class="fa fa-arrow-up" aria-hidden="true"></i></div></div><footer id="page_footer"><div class="footer_wrap"><div class="copyright">&copy;2020 - 2025 by Zujie Liang</div><div class="theme-info">Powered by <a href="https://hexo.io" target="_blank" rel="nofollow noopener">Hexo</a> & <a href="https://github.com/PhosphorW/hexo-theme-academia" target="_blank" rel="nofollow noopener">Academia Theme</a></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery-pjax@latest/jquery.pjax.min.js"></script><script src="/js/main.js"></script></body></html>